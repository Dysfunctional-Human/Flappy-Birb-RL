# Flappyâ€‘Birbâ€‘RL ðŸ¤

A lightweight **Flappy Bird** implementation in Pygame plus a tiny **neuroâ€‘evolution** agent that learns to playâ€”no deepâ€‘learning frameworks required.

https://github.com/Dysfunctional-Human/Flappy-Birb-RL

---

## âœ¨ Features
- **Playable game loop** with smooth physics, sprite animation, and pixelâ€‘perfect collisions.
- **Train & visualize** an evolutionary agent (small MLP) learning in real time.
- **No heavy deps**: just `pygame` and `numpy`.
- **Portable policy**: best agent weights saved as JSON for reuse.

---

## ðŸ—‚ï¸ Project Structure
```
Flappy-Birb-RL/
â”œâ”€ game.py                       # Play the game yourself
â”œâ”€ agent_train_visualize.py      # Train & visualize the evolving agent
â””â”€ components/
   â”œâ”€ agent.py                   # Minimal MLP policy (clone, mutate, act)
   â”œâ”€ bird.py                    # Bird physics + animation
   â”œâ”€ base.py                    # Scrolling ground
   â”œâ”€ pipes.py                   # Pipe generation + collisions
   â””â”€ imgs/                      # Game art
      â”œâ”€ bg.png
      â”œâ”€ base.png
      â”œâ”€ pipe.png
      â”œâ”€ bird1.png
      â”œâ”€ bird2.png
      â””â”€ bird3.png
```

---

## ðŸš€ Quickstart

### 1) Setup
```bash
# (Recommended) Create a virtual environment
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate

# Install dependencies
pip install pygame numpy
```

### 2) Play the game
```bash
python game.py
```
Controls: **Space** to flap. Survive and pass pipes to score.

### 3) Train the agent (with live visualization)
```bash
python agent_train_visualize.py
```
- Watch up to 20 agents on screen while evolution runs generationâ€‘byâ€‘generation.
- The best policy for the current run is saved to **`best_agent_visual.json`**.
---

## ðŸ§  How the Agent Works
The agent is a small MLP (no backprop) optimized via **neuroâ€‘evolution**.

### Observation Space
Each frame, the bird receives a 4â€‘dim vector:
```
[ dx, dy, vy, gap_half ]
```
- `dx`: horizontal distance to the next pipeâ€™s leading edge
- `dy`: vertical distance from the birdâ€™s center to the middle of the pipe gap
- `vy`: current vertical velocity of the bird
- `gap_half`: half the gap size between the upper and lower pipe

### Action Space
- **Binary**: `1` = jump, `0` = do nothing.
- The policy outputs a single scalar; jump if itâ€™s **> 0**.

### Evolutionary Loop
- **Elitism**: top fraction cloned to next generation.
- **Mutationâ€‘only** (no crossover): add Gaussian noise to weights/biases with perâ€‘parameter probability.
- Fixed population & generations; RNG seed for reproducibility.

You can tweak hyperparameters (population size, elites, mutation sigma/prob, hidden sizes, generations, seed) directly in `agent_train_visualize.py`.

---

## ðŸŽ® Game Mechanics (Highâ€‘level)
- **Physics**: quadratic fall with capped terminal step; upward tilt on jump, gradual downward tilt on fall.
- **Pipes**: random vertical position and gap; scroll at constant speed.
- **Collisions**: pixelâ€‘perfect via Pygame masks.
- **HUD**: live generation stats (gen number, alive count, best fitness in run) during training.

## ðŸ™Œ Acknowledgements
- Pygame community & docs.
- Classic Flappy Bird for the inspiration ðŸ’›

